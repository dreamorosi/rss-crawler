{
  "name": "rss-crawler",
  "version": "0.0.1",
  "description": "NodeJS daemon that periodically parses a RSS feed and based on a list of watched items, saves the info of relevant entries in a persistent storage and pushes them to a queue for downstream processing.",
  "main": "src/index.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "setup": "node src/setup.js"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/dreamorosi/rss-crawler.git"
  },
  "author": "Andrea Amorosi",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/dreamorosi/rss-crawler/issues"
  },
  "homepage": "https://github.com/dreamorosi/rss-crawler#readme",
  "dependencies": {
    "inquirer": "^7.3.3",
    "level": "^6.0.1",
    "leveldown": "^5.6.0",
    "levelup": "^4.4.0",
    "node-fetch": "^2.6.1",
    "posix-mq": "^1.1.3",
    "winston": "^3.3.3",
    "xml2js": "^0.4.23",
    "yaml": "^1.10.0"
  }
}
